{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a single classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 1.5.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris csv data using the Pandas library\n",
    "filename = './data/iris.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Pandas returns a dataframe, (df) which could be used for handling the data.\n",
    "# We will however convert the dataframe to numpy arrays for this course as \n",
    "# is also described in the table in the exercise\n",
    "raw_data = df.get_values() \n",
    "\n",
    "# Notice that raw_data both contains the information we want to store in an array\n",
    "# X (the sepal and petal dimensions) and the information that we wish to store \n",
    "# in y (the class labels, that is the iris species).\n",
    "\n",
    "# We start by making the data matrix X by indexing into data.\n",
    "# We know that the attributes are stored in the four columns from inspecting \n",
    "# the file.\n",
    "cols = range(0, 4) \n",
    "X = raw_data[:, cols]\n",
    "\n",
    "# We can extract the attribute names that came from the header of the csv\n",
    "attributeNames = np.asarray(df.columns[cols])\n",
    "\n",
    "# Before we can store the class index, we need to convert the strings that\n",
    "# specify the class of a given object to a numerical value. We start by \n",
    "# extracting the strings for each sample from the raw data loaded from the csv:\n",
    "classLabels = raw_data[:,-1] # -1 takes the last column\n",
    "# Then determine which classes are in the data by finding the set of \n",
    "# unique class labels \n",
    "classNames = np.unique(classLabels)\n",
    "# We can assign each type of Iris class with a number by making a\n",
    "# Python dictionary as so:\n",
    "classDict = dict(zip(classNames,range(len(classNames))))\n",
    "# The function zip simply \"zips\" togetter the classNames with an integer,\n",
    "# like a zipper on a jacket. \n",
    "# For instance, you could zip a list ['A', 'B', 'C'] with ['D', 'E', 'F'] to\n",
    "# get the pairs ('A','D'), ('B', 'E'), and ('C', 'F'). \n",
    "# A Python dictionary is a data object that stores pairs of a key with a value. \n",
    "# This means that when you call a dictionary with a given key, you \n",
    "# get the stored corresponding value. Try highlighting classDict and press F9.\n",
    "# You'll see that the first (key, value)-pair is ('Iris-setosa', 0). \n",
    "# If you look up in the dictionary classDict with the value 'Iris-setosa', \n",
    "# you will get the value 0. Try it with classDict['Iris-setosa']\n",
    "\n",
    "# With the dictionary, we can look up each data objects class label (the string)\n",
    "# in the dictionary, and determine which numerical value that object is \n",
    "# assigned. This is the class index vector y:\n",
    "y = np.array([classDict[cl] for cl in classLabels])\n",
    "# In the above, we have used the concept of \"list comprehension\", which\n",
    "# is a compact way of performing some operations on a list or array.\n",
    "# You could read the line  \"For each class label (cl) in the array of \n",
    "# class labels (classLabels), use the class label (cl) as the key and look up\n",
    "# in the class dictionary (classDict). Store the result for each class label\n",
    "# as an element in a list (because of the brackets []). Finally, convert the \n",
    "# list to a numpy array\". \n",
    "# Try running this to get a feel for the operation: \n",
    "# list = [0,1,2]\n",
    "# new_list = [element+10 for element in list]\n",
    "\n",
    "# We can determine the number of data objects and number of attributes using \n",
    "# the shape of X\n",
    "N, M = X.shape\n",
    "\n",
    "# Finally, the last variable that we need to have the dataset in the \n",
    "# \"standard representation\" for the course, is the number of classes, C:\n",
    "C = len(classNames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossvalidation fold: 1/150\n",
      "Crossvalidation fold: 2/150\n",
      "Crossvalidation fold: 3/150\n",
      "Crossvalidation fold: 4/150\n",
      "Crossvalidation fold: 5/150\n",
      "Crossvalidation fold: 6/150\n",
      "Crossvalidation fold: 7/150\n",
      "Crossvalidation fold: 8/150\n",
      "Crossvalidation fold: 9/150\n",
      "Crossvalidation fold: 10/150\n",
      "Crossvalidation fold: 11/150\n",
      "Crossvalidation fold: 12/150\n",
      "Crossvalidation fold: 13/150\n",
      "Crossvalidation fold: 14/150\n",
      "Crossvalidation fold: 15/150\n",
      "Crossvalidation fold: 16/150\n",
      "Crossvalidation fold: 17/150\n",
      "Crossvalidation fold: 18/150\n",
      "Crossvalidation fold: 19/150\n",
      "Crossvalidation fold: 20/150\n",
      "Crossvalidation fold: 21/150\n",
      "Crossvalidation fold: 22/150\n",
      "Crossvalidation fold: 23/150\n",
      "Crossvalidation fold: 24/150\n",
      "Crossvalidation fold: 25/150\n",
      "Crossvalidation fold: 26/150\n",
      "Crossvalidation fold: 27/150\n",
      "Crossvalidation fold: 28/150\n",
      "Crossvalidation fold: 29/150\n",
      "Crossvalidation fold: 30/150\n",
      "Crossvalidation fold: 31/150\n",
      "Crossvalidation fold: 32/150\n",
      "Crossvalidation fold: 33/150\n",
      "Crossvalidation fold: 34/150\n",
      "Crossvalidation fold: 35/150\n",
      "Crossvalidation fold: 36/150\n",
      "Crossvalidation fold: 37/150\n",
      "Crossvalidation fold: 38/150\n",
      "Crossvalidation fold: 39/150\n",
      "Crossvalidation fold: 40/150\n",
      "Crossvalidation fold: 41/150\n",
      "Crossvalidation fold: 42/150\n",
      "Crossvalidation fold: 43/150\n",
      "Crossvalidation fold: 44/150\n",
      "Crossvalidation fold: 45/150\n",
      "Crossvalidation fold: 46/150\n",
      "Crossvalidation fold: 47/150\n",
      "Crossvalidation fold: 48/150\n",
      "Crossvalidation fold: 49/150\n",
      "Crossvalidation fold: 50/150\n",
      "Crossvalidation fold: 51/150\n",
      "Crossvalidation fold: 52/150\n",
      "Crossvalidation fold: 53/150\n",
      "Crossvalidation fold: 54/150\n",
      "Crossvalidation fold: 55/150\n",
      "Crossvalidation fold: 56/150\n",
      "Crossvalidation fold: 57/150\n",
      "Crossvalidation fold: 58/150\n",
      "Crossvalidation fold: 59/150\n",
      "Crossvalidation fold: 60/150\n",
      "Crossvalidation fold: 61/150\n",
      "Crossvalidation fold: 62/150\n",
      "Crossvalidation fold: 63/150\n",
      "Crossvalidation fold: 64/150\n",
      "Crossvalidation fold: 65/150\n",
      "Crossvalidation fold: 66/150\n",
      "Crossvalidation fold: 67/150\n",
      "Crossvalidation fold: 68/150\n",
      "Crossvalidation fold: 69/150\n",
      "Crossvalidation fold: 70/150\n",
      "Crossvalidation fold: 71/150\n",
      "Crossvalidation fold: 72/150\n",
      "Crossvalidation fold: 73/150\n",
      "Crossvalidation fold: 74/150\n",
      "Crossvalidation fold: 75/150\n",
      "Crossvalidation fold: 76/150\n",
      "Crossvalidation fold: 77/150\n",
      "Crossvalidation fold: 78/150\n",
      "Crossvalidation fold: 79/150\n",
      "Crossvalidation fold: 80/150\n",
      "Crossvalidation fold: 81/150\n",
      "Crossvalidation fold: 82/150\n",
      "Crossvalidation fold: 83/150\n",
      "Crossvalidation fold: 84/150\n",
      "Crossvalidation fold: 85/150\n",
      "Crossvalidation fold: 86/150\n",
      "Crossvalidation fold: 87/150\n",
      "Crossvalidation fold: 88/150\n",
      "Crossvalidation fold: 89/150\n",
      "Crossvalidation fold: 90/150\n",
      "Crossvalidation fold: 91/150\n",
      "Crossvalidation fold: 92/150\n",
      "Crossvalidation fold: 93/150\n",
      "Crossvalidation fold: 94/150\n",
      "Crossvalidation fold: 95/150\n",
      "Crossvalidation fold: 96/150\n",
      "Crossvalidation fold: 97/150\n",
      "Crossvalidation fold: 98/150\n",
      "Crossvalidation fold: 99/150\n",
      "Crossvalidation fold: 100/150\n",
      "Crossvalidation fold: 101/150\n",
      "Crossvalidation fold: 102/150\n",
      "Crossvalidation fold: 103/150\n",
      "Crossvalidation fold: 104/150\n",
      "Crossvalidation fold: 105/150\n",
      "Crossvalidation fold: 106/150\n",
      "Crossvalidation fold: 107/150\n",
      "Crossvalidation fold: 108/150\n",
      "Crossvalidation fold: 109/150\n",
      "Crossvalidation fold: 110/150\n",
      "Crossvalidation fold: 111/150\n",
      "Crossvalidation fold: 112/150\n",
      "Crossvalidation fold: 113/150\n",
      "Crossvalidation fold: 114/150\n",
      "Crossvalidation fold: 115/150\n",
      "Crossvalidation fold: 116/150\n",
      "Crossvalidation fold: 117/150\n",
      "Crossvalidation fold: 118/150\n",
      "Crossvalidation fold: 119/150\n",
      "Crossvalidation fold: 120/150\n",
      "Crossvalidation fold: 121/150\n",
      "Crossvalidation fold: 122/150\n",
      "Crossvalidation fold: 123/150\n",
      "Crossvalidation fold: 124/150\n",
      "Crossvalidation fold: 125/150\n",
      "Crossvalidation fold: 126/150\n",
      "Crossvalidation fold: 127/150\n",
      "Crossvalidation fold: 128/150\n",
      "Crossvalidation fold: 129/150\n",
      "Crossvalidation fold: 130/150\n",
      "Crossvalidation fold: 131/150\n",
      "Crossvalidation fold: 132/150\n",
      "Crossvalidation fold: 133/150\n",
      "Crossvalidation fold: 134/150\n",
      "Crossvalidation fold: 135/150\n",
      "Crossvalidation fold: 136/150\n",
      "Crossvalidation fold: 137/150\n",
      "Crossvalidation fold: 138/150\n",
      "Crossvalidation fold: 139/150\n",
      "Crossvalidation fold: 140/150\n",
      "Crossvalidation fold: 141/150\n",
      "Crossvalidation fold: 142/150\n",
      "Crossvalidation fold: 143/150\n",
      "Crossvalidation fold: 144/150\n",
      "Crossvalidation fold: 145/150\n",
      "Crossvalidation fold: 146/150\n",
      "Crossvalidation fold: 147/150\n",
      "Crossvalidation fold: 148/150\n",
      "Crossvalidation fold: 149/150\n",
      "Crossvalidation fold: 150/150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure, plot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "# requires data from exercise 1.5.1\n",
    "#from ex1_5_1 import *\n",
    "\n",
    "# This script crates predictions from three KNN classifiers using cross-validation\n",
    "\n",
    "# Maximum number of neighbors\n",
    "L=[1, 20, 80]\n",
    "\n",
    "CV = model_selection.LeaveOneOut()\n",
    "i=0\n",
    "\n",
    "# store predictions.\n",
    "yhat = []\n",
    "y_true = []\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "    print('Crossvalidation fold: {0}/{1}'.format(i+1,N))    \n",
    "    \n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # Fit classifier and classify the test points (consider 1 to 40 neighbors)\n",
    "    dy = []\n",
    "    for l in L:\n",
    "        knclassifier = KNeighborsClassifier(n_neighbors=l)\n",
    "        knclassifier.fit(X_train, y_train)\n",
    "        y_est = knclassifier.predict(X_test)\n",
    "\n",
    "        dy.append( y_est )\n",
    "        # errors[i,l-1] = np.sum(y_est[0]!=y_test[0])\n",
    "    dy = np.stack(dy, axis=1)\n",
    "    yhat.append(dy)\n",
    "    y_true.append(y_test)\n",
    "    i+=1\n",
    "\n",
    "yhat = np.concatenate(yhat)\n",
    "y_true = np.concatenate(y_true)\n",
    "yhat[:,0] # predictions made by first classifier.\n",
    "# Compute accuracy here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta point estimate 0.956953642384106  CI:  (0.9194225123023887, 0.9831344032786383)\n"
     ]
    }
   ],
   "source": [
    "from toolbox_02450 import jeffrey_interval\n",
    "#from ex7_1_1 import *\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "[thetahatA, CIA] = jeffrey_interval(y_true, yhat[:,0], alpha=alpha)\n",
    "\n",
    "print(\"Theta point estimate\", thetahatA, \" CI: \", CIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function jeffrey_interval in module toolbox_02450.statistics:\n",
      "\n",
      "jeffrey_interval(y, yhat, alpha=0.05)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(jeffrey_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of McNemars test using alpha= 0.05\n",
      "Comparison matrix n\n",
      "[[143.   1.]\n",
      " [  4.   2.]]\n",
      "Warning, n12+n21 is low: n12+n21= 5.0\n",
      "Approximate 1-alpha confidence interval of theta: [thetaL,thetaU] =  (-0.040463902136215535, 0.00047217032034696516)\n",
      "p-value for two-sided test A and B have same accuracy (exact binomial test): p= 0.375\n",
      "theta = theta_A-theta_B point estimate -0.02  CI:  (-0.040463902136215535, 0.00047217032034696516) p-value 0.375\n"
     ]
    }
   ],
   "source": [
    "from toolbox_02450 import mcnemar\n",
    "#from ex7_1_1 import *\n",
    "\n",
    "# Compute the Jeffreys interval\n",
    "alpha = 0.05\n",
    "[thetahat, CI, p] = mcnemar(y_true, yhat[:,0], yhat[:,1], alpha=alpha)\n",
    "\n",
    "print(\"theta = theta_A-theta_B point estimate\", thetahat, \" CI: \", CI, \"p-value\", p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare two regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran Exercise 5.1.5\n"
     ]
    }
   ],
   "source": [
    "# exercise 5.1.5\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Load Matlab data file and extract variables of interest\n",
    "mat_data = loadmat('./data/wine.mat')\n",
    "X = mat_data['X']\n",
    "y = mat_data['y'].astype(int).squeeze()\n",
    "C = mat_data['C'][0,0]\n",
    "M = mat_data['M'][0,0]\n",
    "N = mat_data['N'][0,0]\n",
    "\n",
    "attributeNames = [i[0][0] for i in mat_data['attributeNames']]\n",
    "classNames = [j[0] for i in mat_data['classNames'] for j in i]\n",
    "\n",
    "\n",
    "# Remove outliers\n",
    "outlier_mask = (X[:,1]>20) | (X[:,7]>10) | (X[:,10]>200)\n",
    "valid_mask = np.logical_not(outlier_mask)\n",
    "X = X[valid_mask,:]\n",
    "y = y[valid_mask]\n",
    "# Remove attribute 12 (Quality score)\n",
    "X = X[:,0:11]\n",
    "attributeNames = attributeNames[0:11]\n",
    "# Update N and M\n",
    "N, M = X.shape\n",
    "\n",
    "print('Ran Exercise 5.1.5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIA (array([0.22305893]), array([0.27726055]))\n",
      "CIB (array([0.23306005]), array([0.35120085]))\n",
      "CI (array([-0.10221926]), array([0.01827784]))\n",
      "P [0.08598555]\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure, plot, xlabel, ylabel, show\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection\n",
    "import sklearn.tree\n",
    "import scipy.stats\n",
    "import numpy as np, scipy.stats as st\n",
    "\n",
    "# requires data from exercise 5.1.5\n",
    "#from ex5_1_5 import *\n",
    "\n",
    "X,y = X[:,:10], X[:,10:]\n",
    "# This script crates predictions from three KNN classifiers using cross-validation\n",
    "\n",
    "test_proportion = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=test_proportion)\n",
    "\n",
    "mA = sklearn.linear_model.LinearRegression().fit(X_train,y_train)\n",
    "mB = sklearn.tree.DecisionTreeRegressor().fit(X_train, y_train)\n",
    "\n",
    "yhatA = mA.predict(X_test)\n",
    "yhatB = mB.predict(X_test)[:,np.newaxis]  #  justsklearnthings\n",
    "\n",
    "# perform statistical comparison of the models\n",
    "# compute z with squared error.\n",
    "zA = np.abs(y_test - yhatA ) ** 2\n",
    "\n",
    "# compute confidence interval of model A\n",
    "alpha = 0.05\n",
    "CIA = st.t.interval(1-alpha, df=len(zA)-1, loc=np.mean(zA), scale=st.sem(zA))  # Confidence interval\n",
    "\n",
    "\n",
    "zB = np.abs(y_test - yhatB ) ** 2\n",
    "alpha = 0.05\n",
    "CIB = st.t.interval(1-alpha, df=len(zB)-1, loc=np.mean(zB), scale=st.sem(zB))  # Confidence interval\n",
    "\n",
    "# Compute confidence interval of z = zA-zB and p-value of Null hypothesis\n",
    "z = zA - zB\n",
    "CI = st.t.interval(1-alpha, len(z)-1, loc=np.mean(z), scale=st.sem(z))  # Confidence interval\n",
    "p = st.t.cdf( -np.abs( np.mean(z) )/st.sem(z), df=len(z)-1)  # p-value\n",
    "\n",
    "print(\"CIA\",CIA)\n",
    "print(\"CIB\",CIB)\n",
    "print(\"CI\",CI)\n",
    "print(\"P\",p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 496.750282,
   "position": {
    "height": "40px",
    "left": "1179.73px",
    "right": "20px",
    "top": "120px",
    "width": "349.986px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
