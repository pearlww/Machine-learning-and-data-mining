{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran Exercise 7.2.3\n"
     ]
    }
   ],
   "source": [
    "# exercise 7.4.3\n",
    "import numpy as np\n",
    "\n",
    "# Load list of names from files\n",
    "fmale = open('./data/male.txt','r')\n",
    "ffemale = open('./data/female.txt','r')\n",
    "mnames = fmale.readlines(); fnames = ffemale.readlines();\n",
    "names = mnames + fnames\n",
    "gender = [0]*len(mnames) + [1]*len(fnames)\n",
    "fmale.close(); ffemale.close();\n",
    "\n",
    "# Extract X, y and the rest of variables. Include only names of >4 characters.\n",
    "X = np.zeros((len(names),4))\n",
    "y = np.zeros((len(names),1))\n",
    "n=0\n",
    "for i in range(0,len(names)):\n",
    "    name = names[i].strip().lower()\n",
    "    if len(name)>3:\n",
    "        X[n,:] = [ord(name[0])-ord('a')+1, ord(name[1])-ord('a')+1, ord(name[-2])-ord('a')+1, ord(name[-1])-ord('a')+1]\n",
    "        y[n,0] = gender[i]\n",
    "        n+=1\n",
    "X = X[0:n,:]; y = y[0:n,:];\n",
    "\n",
    "N, M = X.shape; C = 2\n",
    "attributeNames = ['1st letter', '2nd letter', 'Next-to-last letter', 'Last letter']\n",
    "classNames = ['Female', 'Male'];\n",
    "\n",
    "print('Ran Exercise 7.2.3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error rate: 20.990614174303314%\n",
      "Ran Exercise 7.2.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# exercise 7.4.4\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#from ex7_2_3 import *\n",
    "np.random.seed(2450)\n",
    "y = y.squeeze()\n",
    "0\n",
    "# Naive Bayes classifier parameters\n",
    "alpha = 1.0 # pseudo-count, additive parameter (Laplace correction if 1.0 or Lidtstone smoothing otherwise)\n",
    "fit_prior = True   # uniform prior (change to True to estimate prior from data)\n",
    "\n",
    "# K-fold crossvalidation\n",
    "K = 10\n",
    "CV = model_selection.KFold(n_splits=K,shuffle=True)\n",
    "\n",
    "X = X[:,0:4] # using all 4 letters,\n",
    "# for using e.g. only third letter or first and last try X[:,[2]] and X[:, [0,3]]\n",
    "\n",
    "# We need to specify that the data is categorical.\n",
    "# MultinomialNB does not have this functionality, but we can achieve similar\n",
    "# results by doing a one-hot-encoding - the intermediate steps in in training\n",
    "# the classifier are off, but the final result is corrent.\n",
    "# If we didn't do the converstion MultinomialNB assumes that the numbers are\n",
    "# e.g. discrete counts of tokens. Without the encoding, the value 26 wouldn't\n",
    "# mean \"the token 'z'\", but it would mean 26 counts of some token,\n",
    "# resulting in 1 and 2 meaning a difference in one count of a given token as\n",
    "# opposed to the desired 'a' versus 'b'.\n",
    "X = OneHotEncoder().fit_transform(X=X)\n",
    "\n",
    "errors = np.zeros(K)\n",
    "k=0\n",
    "for train_index, test_index in CV.split(X):\n",
    "    #print('Crossvalidation fold: {0}/{1}'.format(k+1,K))\n",
    "\n",
    "    # extract training and test set for current CV fold\n",
    "    X_train = X[train_index,:]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index,:]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    nb_classifier = MultinomialNB(alpha=alpha,\n",
    "                                  fit_prior=fit_prior)\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    y_est_prob = nb_classifier.predict_proba(X_test)\n",
    "    y_est = np.argmax(y_est_prob,1)\n",
    "\n",
    "    errors[k] = np.sum(y_est!=y_test,dtype=float)/y_test.shape[0]\n",
    "    k+=1\n",
    "\n",
    "# Plot the classification error rate\n",
    "print('Error rate: {0}%'.format(100*np.mean(errors)))\n",
    "\n",
    "print('Ran Exercise 7.2.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "459.567px",
    "left": "1179.73px",
    "right": "20px",
    "top": "120px",
    "width": "349.992px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
